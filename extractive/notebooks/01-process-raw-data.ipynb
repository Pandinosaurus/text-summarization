{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text summarization\n",
    "## 01. Process raw data\n",
    "\n",
    "The objective of this project is to develop a text summarization tool able to create a short version of a given document retaining it most important information. This task is relevant for to access textual information and produce digests of news, social media and reviews. It can also be applied as part of other AI tasks such as answering questions and providing recommendations.\n",
    "\n",
    "The dataset is comprised of more than 92 thousand text documents with CNN stories followed by highlights, which will be used as the summary of each story. Therefore, our first task in data cleaning was to separate the stories from highlights and also carrying on some data cleaning in this process.\n",
    "\n",
    "The CNN dataset was downloaded from New York University, in the version made available by Kyunghyun Cho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to main files\n",
    "ROOT_DIRECTORY ='../data/'\n",
    "RAW_DATA_DIRECTORY = '/raw/'\n",
    "STORIES_PROCESSED_DIRECTORY = 'processed/stories/'\n",
    "SUMMARIES_PROCESSED_DIRECTORY = '/processed/summaries/'\n",
    "TAR_FILE = ROOT_DIRECTORY + RAW_DATA_DIRECTORY + 'stories_raw.tar.gz'\n",
    "directory_raw = ROOT_DIRECTORY + RAW_DATA_DIRECTORY\n",
    "directory_stories = ROOT_DIRECTORY + STORIES_PROCESSED_DIRECTORY\n",
    "directory_summaries = ROOT_DIRECTORY + SUMMARIES_PROCESSED_DIRECTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main text processing tasks\n",
    "- For each story we remove the initial part of the text, which was a CNN office location plus the string '(CNN) -- ' and also the double lines (i.e extra carriage return characters)\n",
    "- For the summaries, we found the highlights using their headers (@highlight) and cleaned extra spaces and carriage return characters. We joined the highlighs to assemble a short summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_data(text):\n",
    "\n",
    "    end_of_story = text.find('@highlight')\n",
    "    # get story and remove first part with CNN office and double dash\n",
    "    story = text[:end_of_story]\n",
    "    index = story.find('(CNN) -- ')\n",
    "    if index > -1:\n",
    "        story = story[index + len('(CNN) -- '):]\n",
    "    # remove double spaces\n",
    "    story = story.replace('\\n\\n', '\\n')\n",
    "\n",
    "    # get the highlights and clean\n",
    "    highlights = text[end_of_story:].split('@highlight')\n",
    "    # strip extra white space around each highlight\n",
    "    highlights = [h.strip() for h in highlights if len(h) > 0]\n",
    "    highlights = [h.strip('\\n') for h in highlights if len(h) > 0]\n",
    "    while '' in highlights:\n",
    "        highlights.remove('')\n",
    "    highlights = [t + '.\\n' for t in highlights]\n",
    "\n",
    "    summary = ''.join(highlights)\n",
    "    return story, summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File number being cleaned 092579\r"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "i = 0\n",
    "\n",
    "t = tarfile.open(TAR_FILE, \"r\")\n",
    "     \n",
    "lst_raw_files = t.getmembers()\n",
    "for filename in lst_raw_files:\n",
    "    try:\n",
    "        \n",
    "        f = t.extractfile(filename)\n",
    "        data = f.read().decode('UTF-8')\n",
    "        \n",
    "    except :\n",
    "        print('ERROR: Did not find {} in tar archive'.format(filename))  \n",
    "    print('File number being cleaned {0:06d}'.format(i), end='\\r', flush = True)\n",
    "    story, summary = read_raw_data(data)\n",
    "    story_name = directory_stories+ 'story' + '{0:06d}'.format(i) +'.txt'\n",
    "    summary_name = directory_summaries + 'summary' + '{0:06d}'.format(i) + '.txt'\n",
    "    # Write file with story\n",
    "    file_story = open(story_name, 'w')\n",
    "    file_story.write(story)\n",
    "    file_story.close()\n",
    "    # Write file with summary\n",
    "    file_summary = open(summary_name, 'w')\n",
    "    file_summary.write(summary)\n",
    "    file_summary.close()\n",
    "    i += 1\n",
    "t.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
